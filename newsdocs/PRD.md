# 뉴스 기사 분석 및 요약 서비스 PRD
(Product Requirements Document)

# 1. 프로젝트 개요 
## 1.1 목표
- 주요 헤드라인을 빠르게 확인할 수 있는 플랫폼 제공
- 선택한 언론 매체의 뉴스를 비교할 수 있는 기능 제공
- 주요 키워드에 대한 AI의 분석 및 요약 제공
- 균형 잡힌 뉴스 소비 촉진

## 1.2 서비스 설명
10개 대표 종합 신문사의 실시간 TOP10 뉴스를 자동으로 수집하고 분석하여 주요 이슈를 한눈에 파악할 수 있는 서비스입니다.

### 대상 신문사
경향신문, 국민일보, 동아일보, 문화일보, 서울신문, 세계일보, 조선일보, 중앙일보, 한겨례, 한국일보

### 주요 기능
- 1시간 단위 자동 크롤링
- 각 신문사 1위 기사 실시간 표시
- 100개 뉴스 기반 키워드 랭킹 생성
- 키워드/언론사 기반 기사 비교 분석
- 주요 키워드 관련 기사 AI 요약

## 1.3 대상 사용자
- 뉴스 독자: 다양한 언론사의 주요 뉴스를 빠르게 파악하고자 하는 사용자
- 연구원/분석가: 언론사별 보도 관점을 비교 분석하고자 하는 전문가
- 일반 사용자: 일상적인 뉴스 하이라이트를 확인하고자 하는 독자

# 2. 사용자 흐름
## 2.1 홈페이지(상위 10개 뉴스)
- 10개 종합 신문의 최신 TOP10 뉴스 즉시 표시
- 순위별 정렬된 목록 보기 형식

## 2.2 키워드 및 미디어 비교 분석
- 키워드 필터링: TOP10 키워드 중 최대 5개 선택 가능
- 언론사 필터링: 10개 종합 신문 중 최대 3개 선택 가능
- 선택된 언론사의 보도 내용 비교
- 키워드 관련 보도 순위 및 차이점 분석
- 선택된 기사들의 LLM 기반 분석 결과 제공

## 2.3 키워드 분석 및 요약
- 키워드 입력/선택
- 관련 기사 자동 수집
- LLM 기반 요약 생성
- 기사 개수 및 동향 요약

## 2.4 요약 보기
- LLM 기반 요약 결과 확인
- 추가 세부정보 요청 가능

# 3. 핵심 기능
## 3.1 뉴스 크롤링
- 1시간 주기 자동 크롤링
- 실시간 키워드 분석
- 크롤링 데이터 정제 및 저장

## 3.2 실시간 랭킹
- 언론사별 TOP10 뉴스를 카드 디자인으로 표시
- 가나다순 분류 및 로고 호버링 효과
- 1~3위 강조 색상 적용으로 가독성 향상

## 3.3 실시간 주요뉴스
- 각 언론사 TOP1 기사 모음
- 가나다순 배열로 한눈에 파악 가능
- 로고와 함께 카드 디자인 적용

## 3.4 키워드 랭킹
- 빈도수 기반 키워드 랭킹 시스템
- 전처리: 한자, 숫자, 괄호 제거
- 정당, 인명, 일반명사 순 우선순위
- Opt.prase를 활용한 구단위 형태소 분석
- stop_words를 통한 불용어 처리

## 3.5 키워드 기반 기사 분석
- TOP10 키워드 관련 기사 모음
- 맞춤형 필터링 및 분석
  - 언론사 최대 3개 선택
  - 키워드 최대 5개 선택
- NewsAnalysisCrew 기반 심층 분석
  - 트렌드 분석: 시간대별 보도 추이 및 언론사별 보도 빈도
  - 관계 분석: 키워드 간 연관성 및 맥락 파악
  - 주요 인사이트: 핵심 쟁점 및 관점 차이 도출

## 3.6 종합 분석 및 요약
- OpenAI GPT API와 LangChain 활용
- 1위 키워드 관련 기사 처리
  - 관련 기사 전체 수집
  - LLM 기반 통합 요약 생성
  - 요약본에 대한 2차 심층 분석
- 키워드 기반 심층 분석
  - 보도 관점: 언론사별 시각과 논조 분석
  - 주요 쟁점: 핵심 이슈와 대립점 도출
  - 종합 분석: 전체적인 맥락과 시사점 제시
- 분석 결과의 요약 제공

# 4. 기술 스택
## 4.1 백엔드 및 API
- Python(3.10+)
  - 주요 로직 구현
  - 데이터 처리 및 분석
  - 크롤링 및 스크래핑

- Django(5.0)
  - MVT 아키텍처 기반 웹 애플리케이션
  - 기본 Django 인증 시스템 활용
  - SQLite(개발) / MySQL(배포) 데이터베이스 연동

## 4.2 데이터 처리 및 AI
- CrewAI
  - Agent 기반 기사 분석
  - 역할별 전문 에이전트 구성
  - 협업 기반 분석 시스템

- OpenAI GPT API + LangChain
  - 기사 요약 및 분석
  - 프롬프트 체인 관리
  - 컨텍스트 기반 응답 생성

- FAISS
  - 의미론적 유사성 검색
  - 벡터 데이터베이스 구축
  - 효율적인 nearest neighbor 검색

## 4.3 프론트엔드
- Django 템플릿
  - 서버 사이드 렌더링
  - 템플릿 상속 구조
  - 동적 컨텐츠 렌더링

- TailwindCSS
  - 유틸리티 퍼스트 CSS
  - 반응형 디자인
  - 다크모드 지원

- JavaScript
  - AJAX 비동기 통신
  - 동적 UI 업데이트
  - 사용자 인터랙션 처리

## 4.4 크롤링 및 데이터 수집
- BeautifulSoup4
  - 정적 페이지 파싱
  - CSS 선택자 기반 데이터 추출
  - HTML 구조 분석

- Selenium
  - 동적 콘텐츠 크롤링
  - JavaScript 렌더링 처리
  - 자동화된 데이터 수집

- Django-CRON
  - 정기적 크롤링 작업
  - 데이터 정리 자동화
  - 시스템 모니터링

## 4.5 성능 최적화
- Redis
  - 캐시 서버
  - 세션 관리
  - 실시간 데이터 처리
  - 크롤링 상태 관리

- 캐시 시스템
  - 메모리 캐시와 파일 백업 이중화
  - 크롤링 중 서비스 연속성 보장
  - 데이터 복구 체계 자동화

- 불용어 처리
  - 커스텀 불용어 사전
  - 효율적인 키워드 추출
  - 텍스트 전처리 최적화

# 5. 성능 및 안정성
## 5.1 캐시 및 백업 시스템
- 메모리 캐시
  - 1시간 동안 유효한 데이터 캐시 유지
  - 캐시 유효 기간 내 빠른 응답 제공
  - 크롤링 중에도 캐시된 데이터로 서비스 제공
- 파일 백업
  - 크롤링 성공 시 자동 백업 저장
  - 크롤링 실패 시 백업 데이터 활용
  - JSON 형식으로 데이터 직렬화 저장
- 데이터 복구 우선순위
  1. 메모리 캐시 확인
  2. 새로운 크롤링 시도
  3. 크롤링 실패 시 백업 데이터 사용
  4. 백업 실패 시 마지막 캐시 재사용

## 5.2 성능 최적화
- 캐싱 전략
  - Redis 활용
  - 계층적 저장
  - 최적화된 처리

# 6. 향후 개선 계획
## 6.1 사용자 관리 시스템
- 키워드 관리 시스템
  - 키워드 출현 빈도 추적
  - 불용어 처리를 통한 키워드 정제
  - 키워드-기사 매핑 관리
- 사용자 활동 분석
  - 읽은 기사 히스토리 관리
  - 관심 키워드 트래킹
  - 선호 언론사 분석

## 6.2 AI 분석 고도화
- GPT-4 모델 적용 검토
- 멀티 에이전트 시스템 확장
- 분석 정확도 향상

## 6.3 크롤링 시스템 개선
- 크롤링 대상 확대
- 실시간 업데이트 구현
- 에러 복구 시스템 강화
- 크롤링 중 서비스 안정성 향상
- 백업 데이터 관리 체계 고도화

## 6.4 사용자 경험 개선
- 반응형 UI/UX 고도화
- 실시간 알림 시스템
- 개인화된 대시보드

## 6.5 데이터 분석 강화
- 고급 통계 분석 도입
- 시각화 도구 추가
- 트렌드 예측 기능

## 6.6 시스템 안정성
- 부하 분산 시스템 구축
- 백업 및 복구 체계 강화
- 모니터링 시스템 고도화

## 6.7 보안 강화
- API 보안 강화
- 데이터 암호화
- 접근 제어 고도화